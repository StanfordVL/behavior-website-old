<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
  <title>BEHAVIOR Challenge 2021</title>

  <!-- Bootstrap -->
  <link href="css/bootstrap.min.css" rel="stylesheet">
  <link href="css/animate.min.css" rel="stylesheet">
  <link href="css/animate.css" rel="stylesheet" />
  <link href="css/prettyPhoto.css" rel="stylesheet">
  <link href="css/style.css" rel="stylesheet">
  <!-- =======================================================
    Theme Name: OnePage
    Theme URL: https://bootstrapmade.com/onepage-multipurpose-bootstrap-template/
    Author: BootstrapMade
    Author URL: https://bootstrapmade.com
  ======================================================= -->

  <script src="https://kit.fontawesome.com/39b62c948b.js" crossorigin="anonymous"></script>
  <link rel="icon" type="image/png" href="media/logo.png"/>
</head>
<style>
  .alignright {
    float: right;
  }
</style>

<body>
  <!-- Header -->
  
  <nav class="navbar navbar-default">
    <div class="container">
      <div class="row">
      <div class="col lg-12">
        <div class="site-logo2">
          <img height="45px" src="media/logo.png"> </img>
          <a class="brand">BEHAVIOR Challenge @ ICCV 2021</a>
          <div>
            <a class="brand">
              <h5 class="pull-left">Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological
                Environments</h5>
              <h5 class="pull-right"> hosted by the Stanford Vision and Learning Lab</h5>
            </a>
          </div>
        </div>


        <!-- /.Navbar-collapse -->
      </div>
      </div>

      <!-- Navbar -->
      <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#menu">
            <i class="fa fa-bars"></i>
          </button>
        </div>
      <div class="collapse navbar-collapse" id="menu">
        <ul class="nav navbar-nav navbar-right">
          <li><a href="index.html">Home</a></li>
          <li><a
              href="https://docs.google.com/document/d/1u2m9Ld6Qo3eG-fvCzuAZN6lHxwpVVBlwLVdzo_WDlNI/edit?usp=sharing">Participant Guide</a>
          </li>
          <li><a href="https://eval.ai/web/challenges/challenge-page/1190/overview">Registration</a></li>
          <li><a href="https://github.com/StanfordVL/BehaviorChallenge2021">Code</a></li>
          <li><a href="activity_list.html">Activity List</a></li>
          <li><a href="#schedule">Schedule</a></li>


        </ul>
      </div>
      
    </div>

  </nav>


  <section id="home">
  </section>
  <section id="about">
  </section>

  <section id="method">
    <div class="container">
      <div class="row method-container">
        <div class="section-header">
          <div class="col-lg-12 col-md-12">
            <h2>What is BEHAVIOR?</h2>
            <p class="section-description">
              As embodied artificial intelligence progresses, we would expect robotic agents to perform interactive 
              activities autonomously, with the versatility and robustness of human agents.
              Where are we in this endeavour? How could we push the limits of embodied AI and measure progress in it?
              We propose to confront embodied AI agents with some of the physical challenges that humans solve in their everyday life: household activities such as washing dishes, picking up toys, or cleaning floors.
<!--               By comparing human and AI performance, we could obtain a picture of the current state of the art of
              embodied AI research. -->
              <b>BEHAVIOR is a challenge in simulation where embodied AI agents need to plan and execute navigation and manipulation
                strategies based on sensor information to fulfill 100 household activities.</b>
            </p>

            <p class="section-description">
              In BEHAVIOR, agents need to navigate and manipulate a simulated
              environment with the goal of accomplishing 100 household activities (check images of the activities <a
                href="media/mosaic_behavior.jpg">here</a>, and the full list <a href="activity_list.html">here</a>). BEHAVIOR tests
              the ability of agents to perceive the environment, plan, and execute complex long-horizon activities that
              involve multiple objects, rooms, and state changes, all with the reproducibility, safety and
              observability offered by a realistic physics simulation. 

              To compare the performance of embodied AI agents to that of humans, we have collected human demonstrations in the same tasks and 
              environments using virtual reality. The demonstrations serve as reference to compare AI solutions, but they also 
              be used to develop them.
            </p>

            <p class="section-description">
              The results for this first BEHAVIOR edition will be presented at ICCV21 on October 17th, during a workshop world-renowned <a href="#workshop_speakers">speakers</a> 
              in perception, embodied intelligence, and robotics.
            </p>
          </div>
        </div>
      </div>
    </div>

  </section>

  <section id="method">
    <div class="container">
      <div class="row method-container">
        <div class="section-header">
          <div class="col-lg-12 col-md-12">
            <h2>What makes BEHAVIOR different?</h2>
            <div class="row">
              <div class="col-lg-4 col-md-12">
                <div class="box2 intro">
                  <h4 class="title"><b>100 Household Activities in <br>Realistically Simulated Homes</b></h4>
                  <!-- <img src="media/behav_web1.mp4" width=300 height=180> </img> -->
                  <video autoplay loop muted width="300">
                      <source src="media/behav_web1.mp4"
                              type="video/mp4">
                      Sorry, your browser doesn't support embedded videos.
                  </video>
                </div>
              </div>
              <div class="col-lg-4 col-md-12">
                <div class="box2 intro">
                  <h4 class="title"><b>Decision Making based on Onboard Sensing for Navigation and Manipulation</b></h4>
                  <!-- <img src="media/tpv.jpg" width=210 height=210> </img> -->
                  <video autoplay loop muted width="300">
                      <source src="media/behav_web2.mp4"
                              type="video/mp4">
                      Sorry, your browser doesn't support embedded videos.
                  </video>
                </div>
              </div>
              <div class="col-lg-4 col-md-12">
                <div class="box2 intro">
                  <h4 class="title"><b>More Complex Interactions<br>than just Pick-and-Place</b></h4>
                  <video autoplay loop muted width="300">
                      <source src="media/state_changes.mp4"
                              type="video/mp4">
                      Sorry, your browser doesn't support embedded videos.
                  </video>
                </div>
              </div>
            </div>
            <ul>
              <li><b>100 Household Activities in Realistically Simulated Homes</b>
                including cleaning, preparing food, tidying, polishing, installing elements, etc. The activities obtained from the American Time Use Survey and 
                approximate the real distribution of tasks performed by humans in their everyday lives.
              </li>
              <li><b>Decision Making based on Onboard Sensing for Navigation and Manipulation:</b>
                the long-horizon activities require to understand the scene, plan a strategy and execute it controlling the motion of the embodied agent, all based 
                on the virtual sensor signals generated by onboard sensors such as RGB-D cameras and position encoders; as close as it gets to the challenges of real-world.
              </li>
              <li><b>More Complex Interactions than just Pick-and-Place:</b> accomplishing the BEHAVIOR activities require changing more than the position of the objects in the environment: they need to be cooked, frozen, soaked, cleaned, ... All these new types of state changes are supported by the provided simulator, iGibson 2.0, and enable completely new types of activities. 
              </li>
            </ul>
            <hr>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section id="method">
    <div class="container">
      <div class="row method-container">
        <div class="section-header">
          <div class="col-lg-12 col-md-12">
            <h2>Getting Started</h2>
            Do you want to participate? Register in our <a href="https://eval.ai/web/challenges/challenge-page/1190">EvalAI site</a>
             and start downloading and installing the required infrastructure: <a href="http://svl.stanford.edu/igibson/docs/installation.html">a new version of iGibson</a>, our simulation environment for interactive tasks, extended now to new object states for BEHAVIOR, the BEHAVIOR Dataset of Objects and the  iGibson2.0 Dataset of Scenes (combined in our <a href="https://storage.googleapis.com/gibson_scenes/behavior_data_bundle.zip">participation bundle</a>), with object and house models to participate in the challenge, and <a href="https://github.com/StanfordVL/BehaviorChallenge2021/">our starter code</a>, with examplest to train againts in the tasks. If you want to use human demonstrations to start developing your solutions, you can also download <a href="human_demonstrations/human_demonstrations.html">the BEHAVIOR Dataset of Human Demonstrations</a> in virtual reality.
            <hr>
          </div>
        </div>
      </div>
  </section>
  <section id="method">
    <div class="container">
      <div class="row method-container">
        <div class="section-header">
          <div class="col-lg-12 col-md-12">

          <h2>Phases and Timeline</h2>
            <ul>
              <li><b>Challenge Launched:</b>
                Teams are able to download all the elements that compose the challenge: the datasets (of objects, scenes, human demonstrations and activity definitions) and the simulation environment iGibson 2.0 that includes the evaluation code.
              </li>
              <li><b>Minival Phase:</b>
                In this phase, participants can test the submission pipeline. The goal is to make sure that their docker image follows our format and can be successfully evaluated in the last phase of the challenge. We will test their solution in one activity instance (minival split), and update the results on the leaderboard.
              </li>
              <li><b>Dev Phase:</b>
                In this phase, participants can develop their solutions, evaluate them on their own with the evaluation code, and send their logs to be verified. Solutions should be evaluated on the <b>dev</b> split of the activity instances. The leaderboard will be updated within 24 hours after the verification of the evaluation logs.
              </li>
              <li><b> Evaluation Phase:</b> This phase decides the ranking. Participants will submit their solutions, we will evaluate them and provide the results in 24 hours confidentially to each participant (the results will NOT be made public until the end of the challenge). We will evaluate on a test split with unseen activity instances.
              </li>
            </ul>
          </div>
          <center>
          <div class="col-lg-12 col-md-12">

            <style>
              table {
                border-collapse: collapse;
                width: 100%;
                justify-content: center;
              }

              th,
              td {
                text-align: left;
                padding: 6px;
              }

              tr:nth-child(odd) {
                background-color: #f2f2f2;
              }
            </style>

            <table style="width:60%">
              <tr>
                <td>BEHAVIOR Challenge Launched</td>
                <td>July 17, 2021</td>
              </tr>
              <tr>
                <td>Minival and Dev Phase Starts</td>
                <td>August 15, 2021</td>
              </tr>
              <tr>
                <td>Minival and Dev Phase Ends, Evaluation Phase Starts</td>
                <td>October 3, 2021</td>
              </tr>

              <tr>
                <td>Evaluation Phase Ends</td>
                <td>October 10, 2021</td>
              </tr>
              <tr>
                <td>BEHAVIOR Workshop and Public Announcement of the Winners @ICCV21</td>
                <td>October 17, 2021</td>
              </tr>
            </table>
          </div>
          </center>
        </div>
      </div>
  </section>

  <br> <br>
  <section id="method">
	<div class="container">
	  <div class="box4 intro">
		  <div class="icon2"><i class="fas fa-envelope"></i></div>
		  <h4 class="title"><b>Join our community!</b></h4>
		  <p>Sign up <a href="https://groups.google.com/g/behavior-benchmark-group"><b>here</b></a>  for latest updates on the challenge and benchmark. </p>
	  </div>
	</div>
</section>

<section id="schedule">
  <div class="container">
    <div class="row method-container">
      <div class="section-header">
        <div class="col-lg-12 col-md-12">
          <hr>

        <h2>Workshop Schedule</h2>
         The workshop is happening at ICCV 2021 on Oct 17, 13:00-18:00 EDT. The detailed schedule is listed as below.
        </div>
        <center>
        <div class="col-lg-12 col-md-12">

          <style>
            table {
              border-collapse: collapse;
              width: 100%;
              justify-content: center;
            }

            th,
            td {
              text-align: left;
              padding: 6px;
            }

            tr:nth-child(odd) {
              background-color: #f2f2f2;
            }
          </style>

          <table style="width:80%">
            <tr>
              <td><b>Time&nbsp;&nbsp;&nbsp;&nbsp;(EST)</b></td>
              <td><b>Speaker </b></td>
              <td><b>Live/Recorded </b></td>
              <td><b>Title of the talk </b></td>
            </tr>
            <tr>
              <td>13:00-13:05</td>
              <td> Organizers </td>
              <td>Live</td>
              <td>Opening Remarks </td>
            </tr>
            <tr>
              <td>13:05-13:40</td>
              <td>Hyowon Gweon </td>
              <td>Live</td>
              <td>Towards socially intelligent, embodied AI: Insights from how humans learn and help others learn</td>
            </tr>
            <tr>
              <td>13:40-14:25</td>
              <td>Leslie Kaelbling </td>
              <td>Live</td>
              <td>Where's the Fork? Representation and Reasoning for a Household Robot</td>
            </tr>
            <tr>
              <td>14:25-15:00</td>
              <td>Kristen Grauman </td>
              <td>Recorded</td>
              <td>TBA</td>
            </tr>
            <tr>
              <td>15:00-15:20</td>
              <td>Organizers </td>
              <td>Live</td>
              <td> Presenting BEHAVIOR Challenge, Winner Announcement </td>
            </tr>
            <tr>
              <td>15:20-15:40</td>
              <td> </td>
              <td> </td>
              <td> Coffee Break </td>
            </tr>
            <tr>
              <td>15:40-16:15</td>
              <td>Chelsea Finn</td>
              <td>Live</td>
              <td>Compositional Task Generalization in Vision-Based Robotic Manipulation </td>
            </tr>
            <tr>
              <td>16:15-16:50</td>
              <td>Jeff Zacks</br>Matthew&nbsp;Bezdek</br>Tan Nguyen</td>
              <td>Recorded</td>
              <td> The Multi-angle Extended Three-D Activities Corpus - A Resource for Human and Robot Event Understanding </td>
            </tr>
            <tr>
              <td>16:50-17:25</td>
              <td>Jeannette Bohg </td>
              <td> Live </td>
              <td> Robots Learning Activities of Daily Living by Watching Humans </td>
            </tr>
            <tr>
              <td>17:25-18:00</td>
              <td>Karen Liu </td>
              <td> Recorded </td>
              <td> Simulating Human Movements for Embodied AI </td>
            </tr>

          </table>
        </div>
        </center>
      </div>
    </div>
</section>

  <section id="method">
    <div class="container">
      <div class="row method-container">
        <div class="section-header">
          <div class="col-lg-12 col-md-12">
            <h2>Workshop Speakers</h2><a id="workshop_speakers"></a>
            The results of the first BEHAVIOR Challenge will be announced during our ICCV21 workshop, where we will also
            enjoy the presentations from the following group of world experts in embodied AI and robotics:</a>
            <br><br>
            <div class="row seven-cols">
              <div class="col-md-1">
                <a href="https://www.cs.utexas.edu/users/grauman/" align="middle">
                  <img
                    src="https://www.cs.utexas.edu/sites/default/files/styles/1200_wide/public/news/grauman1-thumbnail.jpg?itok=4Ox5I46j"
                    class="img-circle img-responsive width=210 height=210">
                  Kristen Grauman
                </a>
              </div>
              <div class="col-md-1"><a href="https://web.stanford.edu/~bohg/" align="middle">
                  <img src="https://web.stanford.edu/~bohg/img/portrait_square.png" class="img-circle img-responsive"
                    width=210 height=210>
                  Jeannette Bohg
                </a></div>
              <div class="col-md-1"><a href="https://ai.stanford.edu/~cbfinn/" align="middle">
                  <img src="https://ai.stanford.edu/~cbfinn/_files/ChelseaFinn_hires.jpg"
                    class="img-circle img-responsive" width=210 height=210>
                  Chelsea Finn
                </a></div>
              <div class="col-md-1"><a href="https://ckllab.stanford.edu/c-karen-liu" align="middle">
                  <img
                    src="https://ckllab.stanford.edu/sites/g/files/sbiybj15216/f/styles/large-scaled/public/karen_headshot_2019_jpeg.png?itok=mB01xRJB"
                    class="img-circle img-responsive" width=210 height=210>
                  Karen Liu
                </a></div>
              <div class="col-md-1"><a href="https://dcl.wustl.edu/people/jzacks/" align="middle">
                  <img src="https://source.wustl.edu/wp-content/uploads/2015/12/Zacks-Jeffrey.jpg"
                    class="img-circle img-responsive" width=210 height=210>
                  Jeff Zacks
                </a></div>
              <div class="col-md-1"><a href="https://web.stanford.edu/~hyo/Home.html/" align="middle">
                  <img
                    src="https://psychology.stanford.edu/sites/psychology/files/styles/hs_medium_square_360x360/public/media/capx/gweon-square1582179036530.jpg?h=b4e301e9&itok=CpQI0I3u"
                    class="img-circle img-responsive" width=210 height=210>
                  Hyowon Gweon
                </a></div>
              <div class="col-md-1"><a href="https://www.csail.mit.edu/person/leslie-kaelbling" align="middle">
                  <img src="https://baicsworkshop.github.io/images/leslie.jpg" class="img-circle img-responsive"
                    width=210 height=210>
                  Leslie Kaelbling
                </a></div>
            </div>
          </div>
          <hr>
        </div>
  </section>
  <section id="method">
    <div class="container">
      <div class="row method-container">
        <div class="section-header">
          <div class="col-lg-12 col-md-12">
            <h2>Organizers and Contact</h2>
            The iGibson Challenge 2021 is organized by the <a href="http://svl.stanford.edu">Stanford Vision and
              Learning Lab</a>. For any inquires, contact us at <a
              href="mailto:behavior.benchmark@gmail.com">behavior.benchmark@gmail.com</a>
            <p></p>
            <div class="row twelve-cols">
              <div class="col-md-1"><a href="http://chengshuli.me" align="middle">
                <img src="media/chengshu.jpg" class="img-circle img-responsive twelve-cols"
                  >
                Chengshu Li
              </a></div>
              <div class="col-md-1">
                <a href="https://www.linkedin.com/in/sanjana-srivastava5/" align="middle">
                  <img src="media/sanjana.jpg" class="img-circle img-responsive"
                  >
                  Sanjana Srivastava
                </a>
              </div>
              <div class="col-md-1">
                <a href="https://github.com/mjlbach/" align="middle">
                  <img src="https://pbs.twimg.com/profile_images/1291846610414997505/J5QTYSTN_400x400.jpg"
                  class="img-circle img-responsive"
                  >
                  Michael Lingelbach
                </a>
              </div>
              <div class="col-md-1">
                <a href="http://fxia.me" align="middle">
                  <img src="media/fei_xia.png" class="img-circle img-responsive"
                  >
                  Fei Xia
                </a>
              </div>

              <div class="col-md-1">
                <a href="https://robertomartinmartin.com/" align="middle">
                  <img src="media/roberto_martinmartin.jpg"
                  class="img-circle img-responsive"
                  >
                  Roberto Martín-Martín
                </a>
              </div>
              <div class="col-md-1">
                <a href="https://www.cemgokmen.com/" align="middle">
                  <img src="https://www.cemgokmen.com/assets/img/bio-photo.jpg" class="img-circle img-responsive"
                  >
                  Cem Gokmen
                </a>
              </div>
              <div class="col-md-1">
                <a href="https://cs.stanford.edu/~shyamal" align="middle">
                  <img src="media/shyamal.jpg" class="img-circle img-responsive"
                  >
                  Shyamal Buch
                </a>
              </div>
              <div class="col-md-1">
                <a href="https://ckllab.stanford.edu/c-karen-liu" align="middle">
                  <img
                    src="https://ckllab.stanford.edu/sites/g/files/sbiybj15216/f/styles/large-scaled/public/karen_headshot_2019_jpeg.png?itok=mB01xRJB"
                    class="img-circle img-responsive"
                  >
                  Karen Liu
                </a>
              </div>
              <div class="col-md-1">
                <a href="http://cvgl.stanford.edu/silvio/" align="middle">
                  <img src="media/silvio_savarese.jpg"
                  class="img-circle img-responsive"
                  >
                  Silvio Savarese
                </a>
              </div>
              <div class="col-md-1">
                <a href="https://web.stanford.edu/~hyo/Home.html" align="middle">
                  <img
                    src="https://bingschool.stanford.edu/sites/bingschool/files/styles/hs_medium_square_360x360/public/media/capx/gweon1582179036530.jpg?h=1641edec&itok=a3TcTu8Y"
                    class="img-circle img-responsive"
                  >
                  Hyowon Gweon
                </a>
              </div>
              <div class="col-md-1">
                <a href="https://jiajunwu.com/" align="middle">
                  <img src="https://jiajunwu.com/images/Jiajun_Wu.jpg" class="img-circle img-responsive"
                  >
                  Jiajun Wu
                </a>
              </div>
              <div class="col-md-1">
                <a href="https://engineering.stanford.edu/people/fei-fei-li" align="middle">
                  <img
                    src="https://engineering.stanford.edu/sites/default/files/styles/large-square/public/9818d36da9c8e04dc45603a690b1e7ce.jpg?itok=s_I8jyVm"
                    class="img-circle img-responsive"
                  >
                  Li Fei-Fei
                </a>
              </div>
            </div>
          </div>
        </div>
  </section>
  
  <section id="method">
    <div class="container">
      <div class="row method-container">
        <div class="section-header">
          <div class="col-lg-12 col-md-12">

            <h2>References</h2>
            <p>[1] <a target="blank" href="https://arxiv.org/abs/2108.03332">BEHAVIOR:
                Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments.</a>
              Sanjana Srivastava, Chengshu Li, Michael Lingelbach, Roberto Martín-Martín, Fei Xia, Kent Vainio, Zheng
              Lian, Cem Gokmen, Shyamal Buch, C. Karen Liu, Silvio Savarese, Hyowon Gweon, Jiajun Wu, Li Fei-Fei.</p>
            <p>[2] <a target="blank" href="https://arxiv.org/abs/2108.03272">iGibson 2.0:
                Object-Centric Simulation for Robot Learning of Everyday Household Tasks
              </a> Chengshu Li, Fei Xia, Roberto Martín-Martín, Michael Lingelbach, Sanjana Srivastava, Bokui Shen, Kent
              Vainio, Cem Gokmen, Gokul Dharan, Tanish Jain, Andrey Kurenkov, C. Karen Liu, Hyowon Gweon, Jiajun Wu, Li
              Fei-Fei, Silvio Savarese.</p>
            <p>[3] <a target="blank" href="https://arxiv.org/abs/2012.02924">iGibson 1.0: A
                Simulation Environment
                for Interactive Tasks in Large Realistic Scenes.</a> Bokui Shen, Fei Xia, Chengshu Li, Roberto
              Martín-Martín,
              Linxi Fan, Guanzhi Wang, Shyamal Buch, Claudia D'Arpino, Sanjana Srivastava, Lyne P Tchapmi, Micael E
              Tchapmi,
              Kent Vainio, Li Fei-Fei, Silvio Savarese, IROS 2021.</p>
          </div>
        </div>
      </div>
  </section>
  <footer id="footer" class="midnight-blue">
    <div class="container">
      <div class="row">
        <div class="col-md-6 col-md-offset-3">
          <div class="text-center">
            <a href="#home" class="scrollup"><i class="fa fa-angle-up fa-3x"></i></a>
          </div>

          <div class="credits">
            <!--
              All the links in the footer should remain intact.
              You can delete the links only if you purchased the pro version.
              Licensing information: https://bootstrapmade.com/license/
              Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=OnePage
            -->
            Template designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
          </div>
        </div>
      </div>
    </div>
  </footer>
  <!--/#footer-->

  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <script src="js/jquery.js"></script>
  <!-- Include all compiled plugins (below), or include individual files as needed -->
  <script src="js/bootstrap.min.js"></script>
  <script src="js/jquery.prettyPhoto.js"></script>
  <script src="js/jquery.isotope.min.js"></script>
  <script src="js/wow.min.js"></script>
  <script src="js/jquery.easing.min.js"></script>
  <script src="js/main.js"></script>

  <script>
    $('#carousel-slider2').carousel({
      interval: false
    })


  </script>

</body>

</html>
